{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9cb0bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ac600f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "os.environ['GROQ_API_KEY'] = os.getenv(\"GROQ_API_KEY\")\n",
    "os.environ['LANGCHAIN_API_KEY'] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ['LANGCHAIN_PROJECT'] = os.getenv(\"LANGCHAIN_PROJECT\")\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = \"true\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d32754c",
   "metadata": {},
   "source": [
    "# Langchain Openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c33daf68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM initialized successfully. client=<openai.resources.chat.completions.completions.Completions object at 0x10c6534c0> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x10d890a30> root_client=<openai.OpenAI object at 0x1058c2e60> root_async_client=<openai.AsyncOpenAI object at 0x10c653af0> model_name='o1-mini' temperature=1.0 model_kwargs={} openai_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"o1-mini\"\n",
    ")\n",
    "\n",
    "print(\"LLM initialized successfully.\", llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6a0fe7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: \"Bharat\" is the native name for India. The capital of Bharat (India) is **New Delhi**.\n"
     ]
    }
   ],
   "source": [
    "result = llm.invoke(\"What is the capital of Bharat?\")\n",
    "print(\"Result:\", result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f529774",
   "metadata": {},
   "source": [
    "# Langchain Groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9761d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result from Groq: \n",
      "<think>\n",
      "Okay, the user is asking, \"What is the capital of Bharat?\" First, I need to recall that \"Bharat\" is the official name for India as per the Constitution of India. So, the question is essentially asking for the capital of India.\n",
      "\n",
      "Now, I remember that India's capital is New Delhi. But wait, sometimes people might confuse Delhi and New Delhi. Let me confirm: Delhi is the larger metropolitan area, while New Delhi is a part of it and the official capital. So the correct answer should be New Delhi.\n",
      "\n",
      "I should also check if there's any recent change, but I don't think so. India has had its capital in New Delhi since 1911 when the British decided to move it from Calcutta. After independence, they kept New Delhi as the capital. \n",
      "\n",
      "Alternatively, maybe the user is using \"Bharat\" in a different context, but I'm pretty sure Bharat is India. To be thorough, I can mention that Bharat is the official short name, so the capital remains New Delhi. \n",
      "\n",
      "No other possibilities come to mind. I think that's solid. Just need to present it clearly.\n",
      "</think>\n",
      "\n",
      "The capital of Bharat (India) is **New Delhi**. \n",
      "\n",
      "\"Bharat\" is one of the official names of the Republic of India, as stated in its Constitution. New Delhi serves as the administrative and political center of the country, housing key government institutions, including the Parliament, the Rashtrapati Bhavan (Presidential Residence), and the Supreme Court.\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "groq_llm = ChatGroq(\n",
    "    model=\"qwen-qwq-32b\"\n",
    ")\n",
    "\n",
    "result=groq_llm.invoke(\"What is the capital of Bharat?\")\n",
    "print(\"Result from Groq:\", result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec4a167",
   "metadata": {},
   "source": [
    "### Prompt Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd64fdf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an AI Engineer. Answer the question based on the context provided.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are an AI Engineer. Answer the question based on the context provided.\"),\n",
    "        (\"user\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "82bb0b8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x11a219e40>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x11a2f3310>, model_name='gemma2-9b-it', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "groq_llm = ChatGroq(\n",
    "    model=\"gemma2-9b-it\"\n",
    ")\n",
    "groq_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dd09e44e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an AI Engineer. Answer the question based on the context provided.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x11a219e40>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x11a2f3310>, model_name='gemma2-9b-it', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### chaining (prompt|model|output)\n",
    "\n",
    "chain = prompt | groq_llm\n",
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2645c195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response from Groq LLM with prompt:\n",
      "\n",
      " As an AI Engineer, I have knowledge of Langsmith.  \n",
      "\n",
      "Langsmith is an open-source platform developed by the Gemma team at Google DeepMind. It's designed to simplify the process of building and deploying large language models (LLMs). \n",
      "\n",
      "Here are some key features of Langsmith:\n",
      "\n",
      "* **User-friendly interface:** Langsmith provides a web-based interface that makes it easier for developers and researchers to interact with LLMs, even without extensive coding experience.\n",
      "* **Modular design:** It follows a modular architecture, allowing users to easily customize and extend the platform with their own tools and components.\n",
      "* **Experiment tracking and management:** Langsmith includes tools for tracking experiments, comparing different model architectures and training parameters, and managing model versions.\n",
      "* **Integration with open-source tools:** It integrates with popular open-source tools like Transformers, ðŸ¤— Datasets, and Weights & Biases, providing a seamless workflow for LLM development.\n",
      "* **Emphasis on transparency and reproducibility:** The platform promotes transparency by making model code, data, and training scripts publicly accessible.\n",
      "\n",
      "Essentially, Langsmith aims to democratize access to LLM development by providing a user-friendly and collaborative platform that lowers the barrier to entry for researchers and developers.\n",
      "\n",
      "\n",
      "Let me know if you have any other questions about Langsmith or LLMs in general! \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response=chain.invoke({\"input\": \"Tell me about Langsmith\"})\n",
    "print(\"Response from Groq LLM with prompt:\\n\\n\", response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63eac94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
